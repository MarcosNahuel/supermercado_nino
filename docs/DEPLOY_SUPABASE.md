si# üöÄ Gu√≠a Completa de Deploy con Supabase

## üìã Tabla de Contenidos

1. [Introducci√≥n](#introducci√≥n)
2. [Problema Original](#problema-original)
3. [Soluci√≥n con Supabase](#soluci√≥n-con-supabase)
4. [Configuraci√≥n Inicial](#configuraci√≥n-inicial)
5. [Migraci√≥n de Datos](#migraci√≥n-de-datos)
6. [Deploy en Streamlit Cloud](#deploy-en-streamlit-cloud)
7. [Mantenimiento](#mantenimiento)

---

## üéØ Introducci√≥n

Esta gu√≠a documenta la soluci√≥n implementada para superar las limitaciones de tama√±o de GitHub (100MB) al deployar el dashboard de Supermercado NINO.

### Archivos Actualizados en Esta Soluci√≥n

- ‚úÖ `FASE1_ANALISIS_COMPLETO.py` - Actualizado para usar `SERIE_COMPROBANTES_COMPLETOS2.csv`
- ‚úÖ `app_streamlit_supabase.py` - Nueva versi√≥n con soporte para Supabase
- ‚úÖ `scripts/migrate_to_supabase.py` - Script de migraci√≥n de datos
- ‚úÖ `requirements.txt` - Dependencias actualizadas
- ‚úÖ `.env` y `.env.example` - Configuraci√≥n de credenciales
- ‚úÖ `.gitignore` - Excluye archivos sensibles

---

## ‚ö†Ô∏è Problema Original

### Situaci√≥n

- **Archivo CSV:** `SERIE_COMPROBANTES_COMPLETOS2.csv`
- **Tama√±o:** 378 MB (2,944,660 registros)
- **L√≠mite de GitHub:** 100 MB por archivo
- **Resultado:** Imposible subir el dataset al repositorio

### Intentos Previos

- ‚ùå Git LFS (Git Large File Storage) - Requiere pago para ancho de banda
- ‚ùå Compresi√≥n - Archivo sigue siendo muy grande
- ‚ùå GitHub Releases - Mismo l√≠mite de 100 MB

---

## ‚úÖ Soluci√≥n con Supabase

### Por Qu√© Supabase

1. **Base de Datos PostgreSQL en la Nube:** Gratuita hasta 500MB
2. **API REST Autom√°tica:** Acceso inmediato a los datos
3. **Sin L√≠mites de Tama√±o de Archivo:** Los datos est√°n en una base de datos
4. **Integraci√≥n Simple con Streamlit:** SDK de Python oficial
5. **Gratuito para Proyectos Peque√±os:** Perfecto para dashboards PYME

### Arquitectura de la Soluci√≥n

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CSV Local (378MB) ‚îÇ
‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îÇ migrate_to_supabase.py
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Supabase DB   ‚îÇ
    ‚îÇ  (PostgreSQL)   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îÇ Supabase API
              ‚ñº
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ  Streamlit   ‚îÇ
       ‚îÇ  Cloud App   ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Configuraci√≥n Inicial

### 1. Crear Cuenta en Supabase

1. Ve a [https://supabase.com](https://supabase.com)
2. Registra una cuenta gratuita
3. Crea un nuevo proyecto:
   - Nombre: `supermercado-nino`
   - Base de datos: (genera una contrase√±a fuerte)
   - Regi√≥n: South America (m√°s cercano)

### 2. Obtener Credenciales

En el Dashboard de Supabase:

1. Ve a **Settings** > **API**
2. Copia:
   - **Project URL:** `https://xxxxx.supabase.co`
   - **anon public key:** `eyJhbGciOiJIUzI1NiI...`

### 3. Configurar Variables de Entorno

#### Opci√≥n A: Archivo .env (desarrollo local)

Crea `.env` en la ra√≠z del proyecto:

```bash
SUPABASE_URL=https://tu-proyecto.supabase.co
SUPABASE_KEY=tu-anon-key-aqui
```

#### Opci√≥n B: Streamlit Secrets (producci√≥n)

En Streamlit Cloud, ve a **Settings** > **Secrets** y agrega:

```toml
SUPABASE_URL = "https://tu-proyecto.supabase.co"
SUPABASE_KEY = "tu-anon-key-aqui"
```

### 4. Instalar Dependencias

```bash
pip install -r requirements.txt
```

Aseg√∫rate de que `requirements.txt` incluya:

```
supabase>=2.0.0
python-dotenv>=1.0.0
tqdm>=4.66.0
```

---

## üìä Migraci√≥n de Datos

### Paso 1: Crear Tablas en Supabase

En el **SQL Editor** de Supabase, ejecuta:

```sql
-- Tabla de KPIs por per√≠odo
CREATE TABLE kpi_periodo (
    id SERIAL PRIMARY KEY,
    periodo VARCHAR(7) NOT NULL,
    ventas DECIMAL(15, 2),
    margen DECIMAL(15, 2),
    tickets INTEGER,
    ticket_promedio DECIMAL(15, 2),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de KPIs por categor√≠a
CREATE TABLE kpi_categoria (
    id SERIAL PRIMARY KEY,
    categoria VARCHAR(100) NOT NULL,
    rentabilidad_pct DECIMAL(5, 2),
    ventas DECIMAL(15, 2),
    margen DECIMAL(15, 2),
    unidades INTEGER,
    tickets INTEGER,
    pct_ventas DECIMAL(5, 2),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de KPIs por d√≠a de semana
CREATE TABLE kpi_dia_semana (
    id SERIAL PRIMARY KEY,
    dia_semana VARCHAR(20) NOT NULL,
    ventas DECIMAL(15, 2),
    tickets INTEGER,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de Pareto (productos ABC)
CREATE TABLE pareto_productos (
    id SERIAL PRIMARY KEY,
    producto_id VARCHAR(50) NOT NULL,
    descripcion VARCHAR(200),
    categoria VARCHAR(100),
    ventas DECIMAL(15, 2),
    unidades INTEGER,
    margen DECIMAL(15, 2),
    ventas_acumuladas DECIMAL(15, 2),
    pct_acumulado DECIMAL(5, 2),
    clasificacion_abc VARCHAR(1),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de perfiles de clusters
CREATE TABLE perfiles_clusters (
    id SERIAL PRIMARY KEY,
    cluster INTEGER NOT NULL,
    cantidad_tickets INTEGER,
    ticket_promedio DECIMAL(15, 2),
    items_promedio DECIMAL(5, 2),
    margen_promedio DECIMAL(15, 2),
    pct_fin_semana DECIMAL(5, 2),
    pct_tickets DECIMAL(5, 2),
    etiqueta VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de reglas de asociaci√≥n
CREATE TABLE reglas_asociacion (
    id SERIAL PRIMARY KEY,
    antecedents TEXT,
    consequents TEXT,
    support DECIMAL(10, 6),
    confidence DECIMAL(10, 6),
    lift DECIMAL(10, 4),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de tickets (resumen)
CREATE TABLE tickets (
    id SERIAL PRIMARY KEY,
    ticket_id VARCHAR(50) NOT NULL UNIQUE,
    monto_total_ticket DECIMAL(15, 2),
    items_ticket INTEGER,
    margen_ticket DECIMAL(15, 2),
    fecha TIMESTAMP,
    periodo VARCHAR(7),
    dia_semana VARCHAR(20),
    es_fin_semana BOOLEAN,
    cluster INTEGER,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de items de ventas (m√°s pesada - opcional)
CREATE TABLE items_ventas (
    id SERIAL PRIMARY KEY,
    fecha TIMESTAMP,
    ticket_id VARCHAR(50),
    producto_id VARCHAR(50),
    categoria VARCHAR(100),
    descripcion VARCHAR(200),
    cantidad DECIMAL(10, 3),
    importe_total DECIMAL(15, 2),
    precio_unitario DECIMAL(15, 2),
    created_at TIMESTAMP DEFAULT NOW()
);

-- √çndices para mejorar rendimiento
CREATE INDEX idx_tickets_fecha ON tickets(fecha);
CREATE INDEX idx_tickets_id ON tickets(ticket_id);
CREATE INDEX idx_items_ticket ON items_ventas(ticket_id);
CREATE INDEX idx_items_categoria ON items_ventas(categoria);
CREATE INDEX idx_items_fecha ON items_ventas(fecha);
CREATE INDEX idx_pareto_clasificacion ON pareto_productos(clasificacion_abc);
```

### Paso 2: Ejecutar Script de Migraci√≥n

```bash
python scripts/migrate_to_supabase.py
```

#### Qu√© Hace el Script

1. **Lee credenciales** desde `.env`
2. **Conecta a Supabase**
3. **Migra tablas ligeras** (KPIs, Pareto, Clusters)
4. **Migra tickets** en chunks de 1,000 registros
5. **Migra items** en chunks de 500 registros (modo demo: primeros 100k)
6. **Muestra progreso** con barra de tqdm

#### Notas Importantes

- ‚è±Ô∏è **Tiempo estimado:** 30-60 minutos para migraci√≥n completa
- üíæ **Modo demo:** Por defecto migra solo 100k items (quita el l√≠mite para full migration)
- üîÑ **Re-ejecutable:** Puedes detener y reanudar (si las tablas est√°n vac√≠as)
- ‚ùå **Duplicados:** Si la tabla ya tiene datos, fallar√° (elimina registros primero)

### Paso 3: Verificar Datos

1. Ve al **Table Editor** en Supabase Dashboard
2. Verifica que las tablas tengan datos:
   - `kpi_periodo`: ~13 registros (meses)
   - `kpi_categoria`: ~45 registros (categor√≠as)
   - `pareto_productos`: ~10,000 registros (productos)
   - `tickets`: ~306,000 registros
   - `items_ventas`: ~100,000 registros (modo demo) o ~3M (full)

---

## ‚òÅÔ∏è Deploy en Streamlit Cloud

### Paso 1: Preparar Repositorio

#### 1. Aseg√∫rate de que `.gitignore` excluye archivos sensibles:

```gitignore
# Environment variables
.env
.env.local
.streamlit/secrets.toml

# Data files
data/raw/
*.csv
!data/sample/**
```

#### 2. Commit y push de cambios:

```bash
git add .
git commit -m "Implementa integraci√≥n con Supabase para deploy sin l√≠mites de tama√±o"
git push origin main
```

### Paso 2: Deploy en Streamlit Cloud

1. Ve a [https://streamlit.io/cloud](https://streamlit.io/cloud)
2. Haz clic en **New app**
3. Selecciona tu repositorio: `MarcosNahuel/supermercado_nino`
4. **Main file path:** `app_streamlit_supabase.py`
5. **Python version:** 3.10 (recomendado)

### Paso 3: Configurar Secrets

En **Advanced settings** > **Secrets**:

```toml
SUPABASE_URL = "https://yebiszzkrgapfqwngbwj.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InllYmlzenprcmdhcGZxd25nYndqIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzkxMDM1ODEsImV4cCI6MjA1NDY3OTU4MX0.4iQFcFwQaH5NDV3op0AUxWxkFjNXVCL0degCThMiU8E"
```

### Paso 4: Deploy

- Haz clic en **Deploy!**
- Espera 3-5 minutos
- ‚úÖ La app estar√° disponible en: `https://tu-app.streamlit.app`

---

## üîÑ Mantenimiento

### Actualizar Datos

Cuando tengas nuevos datos:

1. **Actualiza el CSV local** con los datos nuevos
2. **Borra tablas en Supabase** (SQL Editor):

```sql
TRUNCATE TABLE kpi_periodo, kpi_categoria, kpi_dia_semana,
              pareto_productos, perfiles_clusters, reglas_asociacion,
              tickets, items_ventas CASCADE;
```

3. **Re-ejecuta la migraci√≥n:**

```bash
python scripts/migrate_to_supabase.py
```

4. **Reinicia la app en Streamlit Cloud** (se recarga autom√°ticamente tras 1 hora de cache)

### Monitoreo

#### En Supabase Dashboard:

- **Database** > **Database**: Ver uso de almacenamiento
- **API**: Ver requests y l√≠mites
- **Logs**: Depurar errores

#### L√≠mites del Plan Gratuito:

- üìä **Almacenamiento:** 500 MB
- üîå **API Calls:** 50,000 requests/mes
- üë• **Usuarios activos:** Ilimitados (anon key)

### Optimizaci√≥n

Si alcanzas l√≠mites, considera:

1. **Implementar paginaci√≥n** en queries grandes
2. **Aumentar cache TTL** en Streamlit (de 1 hora a 24 horas)
3. **Eliminar columnas innecesarias** (reduce tama√±o de DB)
4. **Agregar m√°s √≠ndices** para queries frecuentes
5. **Upgrade a plan Pro** ($25/mes - 8GB storage)

---

## üéØ Resultados

### Antes (Sin Supabase)

‚ùå CSV de 378MB no se pod√≠a subir a GitHub
‚ùå Imposible deployar en Streamlit Cloud
‚ùå Alternativas (Git LFS) eran costosas o complejas

### Despu√©s (Con Supabase)

‚úÖ Datos alojados en Supabase (gratis)
‚úÖ Repositorio limpio (solo c√≥digo, sin CSVs grandes)
‚úÖ Deploy exitoso en Streamlit Cloud
‚úÖ App carga datos desde la nube en <2 segundos
‚úÖ Escalable y mantenible

---

## üìû Soporte

Si tienes problemas:

1. **Revisa logs en Supabase Dashboard:** Settings > Logs
2. **Verifica credenciales:** Aseg√∫rate de que SUPABASE_URL y SUPABASE_KEY sean correctos
3. **Chequea l√≠mites:** Database > Database Usage
4. **Consulta documentaci√≥n:** [https://supabase.com/docs](https://supabase.com/docs)

---

## üìö Referencias

- [Supabase Documentation](https://supabase.com/docs)
- [Supabase Python Client](https://github.com/supabase-community/supabase-py)
- [Streamlit Secrets Management](https://docs.streamlit.io/streamlit-community-cloud/deploy-your-app/secrets-management)
- [PostgreSQL Best Practices](https://wiki.postgresql.org/wiki/Don%27t_Do_This)

---

**Autor:** pymeinside.com
**Fecha:** Octubre 2025
**Versi√≥n:** 2.0
**Proyecto:** Supermercado NINO - Dashboard de An√°lisis de Ventas
