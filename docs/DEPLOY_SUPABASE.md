si# ğŸš€ GuÃ­a Completa de Deploy con Supabase

## ğŸ“‹ Tabla de Contenidos

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Problema Original](#problema-original)
3. [SoluciÃ³n con Supabase](#soluciÃ³n-con-supabase)
4. [ConfiguraciÃ³n Inicial](#configuraciÃ³n-inicial)
5. [MigraciÃ³n de Datos](#migraciÃ³n-de-datos)
6. [Deploy en Streamlit Cloud](#deploy-en-streamlit-cloud)
7. [Mantenimiento](#mantenimiento)

---

## ğŸ¯ IntroducciÃ³n

Esta guÃ­a documenta la soluciÃ³n implementada para superar las limitaciones de tamaÃ±o de GitHub (100MB) al deployar el dashboard de Supermercado NINO.

### Archivos Actualizados en Esta SoluciÃ³n

- âœ… `FASE1_ANALISIS_COMPLETO.py` - Actualizado para usar `SERIE_COMPROBANTES_COMPLETOS2.csv`
- âœ… `app_streamlit_supabase.py` - Nueva versiÃ³n con soporte para Supabase
- âœ… `scripts/migrate_to_supabase.py` - Script de migraciÃ³n de datos
- âœ… `requirements.txt` - Dependencias actualizadas
- âœ… `.env` y `.env.example` - ConfiguraciÃ³n de credenciales
- âœ… `.gitignore` - Excluye archivos sensibles

---

## âš ï¸ Problema Original

### SituaciÃ³n

- **Archivo CSV:** `SERIE_COMPROBANTES_COMPLETOS2.csv`
- **TamaÃ±o:** 378 MB (2,944,660 registros)
- **LÃ­mite de GitHub:** 100 MB por archivo
- **Resultado:** Imposible subir el dataset al repositorio

### Intentos Previos

- âŒ Git LFS (Git Large File Storage) - Requiere pago para ancho de banda
- âŒ CompresiÃ³n - Archivo sigue siendo muy grande
- âŒ GitHub Releases - Mismo lÃ­mite de 100 MB

---

## âœ… SoluciÃ³n con Supabase

### Por QuÃ© Supabase

1. **Base de Datos PostgreSQL en la Nube:** Gratuita hasta 500MB
2. **API REST AutomÃ¡tica:** Acceso inmediato a los datos
3. **Sin LÃ­mites de TamaÃ±o de Archivo:** Los datos estÃ¡n en una base de datos
4. **IntegraciÃ³n Simple con Streamlit:** SDK de Python oficial
5. **Gratuito para Proyectos PequeÃ±os:** Perfecto para dashboards PYME

### Arquitectura de la SoluciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV Local (378MB) â”‚
â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ migrate_to_supabase.py
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Supabase DB   â”‚
    â”‚  (PostgreSQL)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ Supabase API
              â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Streamlit   â”‚
       â”‚  Cloud App   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ ConfiguraciÃ³n Inicial

### 1. Crear Cuenta en Supabase

1. Ve a [https://supabase.com](https://supabase.com)
2. Registra una cuenta gratuita
3. Crea un nuevo proyecto:
   - Nombre: `supermercado-nino`
   - Base de datos: (genera una contraseÃ±a fuerte)
   - RegiÃ³n: South America (mÃ¡s cercano)

### 2. Obtener Credenciales

En el Dashboard de Supabase:

1. Ve a **Settings** > **API**
2. Copia:
   - **Project URL:** `https://xxxxx.supabase.co`
   - **anon public key:** `eyJhbGciOiJIUzI1NiI...`

### 3. Configurar Variables de Entorno

#### OpciÃ³n A: Archivo .env (desarrollo local)

Crea `.env` en la raÃ­z del proyecto:

```bash
SUPABASE_URL=https://tu-proyecto.supabase.co
SUPABASE_KEY=tu-anon-key-aqui
```

#### OpciÃ³n B: Streamlit Secrets (producciÃ³n)

En Streamlit Cloud, ve a **Settings** > **Secrets** y agrega:

```toml
SUPABASE_URL = "https://tu-proyecto.supabase.co"
SUPABASE_KEY = "tu-anon-key-aqui"
```

### 4. Instalar Dependencias

```bash
pip install -r requirements.txt
```

AsegÃºrate de que `requirements.txt` incluya:

```
supabase>=2.0.0
python-dotenv>=1.0.0
tqdm>=4.66.0
```

---

## ğŸ“Š MigraciÃ³n de Datos

### Paso 1: Crear Tablas en Supabase

En el **SQL Editor** de Supabase, ejecuta:

```sql
-- Tabla de KPIs por perÃ­odo
CREATE TABLE kpi_periodo (
    id SERIAL PRIMARY KEY,
    periodo VARCHAR(7) NOT NULL,
    ventas DECIMAL(15, 2),
    margen DECIMAL(15, 2),
    tickets INTEGER,
    ticket_promedio DECIMAL(15, 2),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de KPIs por categorÃ­a
CREATE TABLE kpi_categoria (
    id SERIAL PRIMARY KEY,
    categoria VARCHAR(100) NOT NULL,
    rentabilidad_pct DECIMAL(5, 2),
    ventas DECIMAL(15, 2),
    margen DECIMAL(15, 2),
    unidades INTEGER,
    tickets INTEGER,
    pct_ventas DECIMAL(5, 2),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de KPIs por dÃ­a de semana
CREATE TABLE kpi_dia_semana (
    id SERIAL PRIMARY KEY,
    dia_semana VARCHAR(20) NOT NULL,
    ventas DECIMAL(15, 2),
    tickets INTEGER,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de Pareto (productos ABC)
CREATE TABLE pareto_productos (
    id SERIAL PRIMARY KEY,
    producto_id VARCHAR(50) NOT NULL,
    descripcion VARCHAR(200),
    categoria VARCHAR(100),
    ventas DECIMAL(15, 2),
    unidades INTEGER,
    margen DECIMAL(15, 2),
    ventas_acumuladas DECIMAL(15, 2),
    pct_acumulado DECIMAL(5, 2),
    clasificacion_abc VARCHAR(1),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de perfiles de clusters
CREATE TABLE perfiles_clusters (
    id SERIAL PRIMARY KEY,
    cluster INTEGER NOT NULL,
    cantidad_tickets INTEGER,
    ticket_promedio DECIMAL(15, 2),
    items_promedio DECIMAL(5, 2),
    margen_promedio DECIMAL(15, 2),
    pct_fin_semana DECIMAL(5, 2),
    pct_tickets DECIMAL(5, 2),
    etiqueta VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de reglas de asociaciÃ³n
CREATE TABLE reglas_asociacion (
    id SERIAL PRIMARY KEY,
    antecedents TEXT,
    consequents TEXT,
    support DECIMAL(10, 6),
    confidence DECIMAL(10, 6),
    lift DECIMAL(10, 4),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de tickets (resumen)
CREATE TABLE tickets (
    id SERIAL PRIMARY KEY,
    ticket_id VARCHAR(50) NOT NULL UNIQUE,
    monto_total_ticket DECIMAL(15, 2),
    items_ticket INTEGER,
    margen_ticket DECIMAL(15, 2),
    fecha TIMESTAMP,
    periodo VARCHAR(7),
    dia_semana VARCHAR(20),
    es_fin_semana BOOLEAN,
    cluster INTEGER,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabla de items de ventas (mÃ¡s pesada - opcional)
CREATE TABLE items_ventas (
    id SERIAL PRIMARY KEY,
    fecha TIMESTAMP,
    ticket_id VARCHAR(50),
    producto_id VARCHAR(50),
    categoria VARCHAR(100),
    descripcion VARCHAR(200),
    cantidad DECIMAL(10, 3),
    importe_total DECIMAL(15, 2),
    precio_unitario DECIMAL(15, 2),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Ãndices para mejorar rendimiento
CREATE INDEX idx_tickets_fecha ON tickets(fecha);
CREATE INDEX idx_tickets_id ON tickets(ticket_id);
CREATE INDEX idx_items_ticket ON items_ventas(ticket_id);
CREATE INDEX idx_items_categoria ON items_ventas(categoria);
CREATE INDEX idx_items_fecha ON items_ventas(fecha);
CREATE INDEX idx_pareto_clasificacion ON pareto_productos(clasificacion_abc);
```

### Paso 2: Ejecutar Script de MigraciÃ³n

```bash
python scripts/migrate_to_supabase.py
```

#### QuÃ© Hace el Script

1. **Lee credenciales** desde `.env`
2. **Conecta a Supabase**
3. **Migra tablas ligeras** (KPIs, Pareto, Clusters)
4. **Migra tickets** en chunks de 1,000 registros
5. **Migra items** en chunks de 500 registros (modo demo: primeros 100k)
6. **Muestra progreso** con barra de tqdm

#### Notas Importantes

- â±ï¸ **Tiempo estimado:** 30-60 minutos para migraciÃ³n completa
- ğŸ’¾ **Modo demo:** Por defecto migra solo 100k items (quita el lÃ­mite para full migration)
- ğŸ”„ **Re-ejecutable:** Puedes detener y reanudar (si las tablas estÃ¡n vacÃ­as)
- âŒ **Duplicados:** Si la tabla ya tiene datos, fallarÃ¡ (elimina registros primero)

### Paso 3: Verificar Datos

1. Ve al **Table Editor** en Supabase Dashboard
2. Verifica que las tablas tengan datos:
   - `kpi_periodo`: ~13 registros (meses)
   - `kpi_categoria`: ~45 registros (categorÃ­as)
   - `pareto_productos`: ~10,000 registros (productos)
   - `tickets`: ~306,000 registros
   - `items_ventas`: ~100,000 registros (modo demo) o ~3M (full)

---

## â˜ï¸ Deploy en Streamlit Cloud

### Paso 1: Preparar Repositorio

#### 1. AsegÃºrate de que `.gitignore` excluye archivos sensibles:

```gitignore
# Environment variables
.env
.env.local
.streamlit/secrets.toml

# Data files
data/raw/
*.csv
!data/sample/**
```

#### 2. Commit y push de cambios:

```bash
git add .
git commit -m "Implementa integraciÃ³n con Supabase para deploy sin lÃ­mites de tamaÃ±o"
git push origin main
```

### Paso 2: Deploy en Streamlit Cloud

1. Ve a [https://streamlit.io/cloud](https://streamlit.io/cloud)
2. Haz clic en **New app**
3. Selecciona tu repositorio: `MarcosNahuel/supermercado_nino`
4. **Main file path:** `app_streamlit_supabase.py`
5. **Python version:** 3.10 (recomendado)

### Paso 3: Configurar Secrets

En **Advanced settings** > **Secrets**:

```toml
SUPABASE_URL = "https://yebiszzkrgapfqwngbwj.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InllYmlzenprcmdhcGZxd25nYndqIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzkxMDM1ODEsImV4cCI6MjA1NDY3OTU4MX0.4iQFcFwQaH5NDV3op0AUxWxkFjNXVCL0degCThMiU8E"
```

### Paso 4: Deploy

- Haz clic en **Deploy!**
- Espera 3-5 minutos
- âœ… La app estarÃ¡ disponible en: `https://tu-app.streamlit.app`

---

## ğŸ”„ Mantenimiento

### Actualizar Datos

Cuando tengas nuevos datos:

1. **Actualiza el CSV local** con los datos nuevos
2. **Borra tablas en Supabase** (SQL Editor):

```sql
TRUNCATE TABLE kpi_periodo, kpi_categoria, kpi_dia_semana,
              pareto_productos, perfiles_clusters, reglas_asociacion,
              tickets, items_ventas CASCADE;
```

3. **Re-ejecuta la migraciÃ³n:**

```bash
python scripts/migrate_to_supabase.py
```

4. **Reinicia la app en Streamlit Cloud** (se recarga automÃ¡ticamente tras 1 hora de cache)

### Monitoreo

#### En Supabase Dashboard:

- **Database** > **Database**: Ver uso de almacenamiento
- **API**: Ver requests y lÃ­mites
- **Logs**: Depurar errores

#### LÃ­mites del Plan Gratuito:

- ğŸ“Š **Almacenamiento:** 500 MB
- ğŸ”Œ **API Calls:** 50,000 requests/mes
- ğŸ‘¥ **Usuarios activos:** Ilimitados (anon key)

### OptimizaciÃ³n

Si alcanzas lÃ­mites, considera:

1. **Implementar paginaciÃ³n** en queries grandes
2. **Aumentar cache TTL** en Streamlit (de 1 hora a 24 horas)
3. **Eliminar columnas innecesarias** (reduce tamaÃ±o de DB)
4. **Agregar mÃ¡s Ã­ndices** para queries frecuentes
5. **Upgrade a plan Pro** ($25/mes - 8GB storage)

---

## ğŸ¯ Resultados

### Antes (Sin Supabase)

âŒ CSV de 378MB no se podÃ­a subir a GitHub
âŒ Imposible deployar en Streamlit Cloud
âŒ Alternativas (Git LFS) eran costosas o complejas

### DespuÃ©s (Con Supabase)

âœ… Datos alojados en Supabase (gratis)
âœ… Repositorio limpio (solo cÃ³digo, sin CSVs grandes)
âœ… Deploy exitoso en Streamlit Cloud
âœ… App carga datos desde la nube en <2 segundos
âœ… Escalable y mantenible

---

## ğŸ“ Soporte

Si tienes problemas:

1. **Revisa logs en Supabase Dashboard:** Settings > Logs
2. **Verifica credenciales:** AsegÃºrate de que SUPABASE_URL y SUPABASE_KEY sean correctos
3. **Chequea lÃ­mites:** Database > Database Usage
4. **Consulta documentaciÃ³n:** [https://supabase.com/docs](https://supabase.com/docs)

---

## ğŸ“š Referencias

- [Supabase Documentation](https://supabase.com/docs)
- [Supabase Python Client](https://github.com/supabase-community/supabase-py)
- [Streamlit Secrets Management](https://docs.streamlit.io/streamlit-community-cloud/deploy-your-app/secrets-management)
- [PostgreSQL Best Practices](https://wiki.postgresql.org/wiki/Don%27t_Do_This)

---

**Autor:** pymeinside.com
**Fecha:** Octubre 2025
**VersiÃ³n:** 2.0
**Proyecto:** Supermercado NINO - Dashboard de AnÃ¡lisis de Ventas
